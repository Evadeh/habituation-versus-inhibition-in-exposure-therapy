---
title: "Habituation versus inhibition in exposure therapy - literature synthesis"
author: "Pepijn van der Hulle, Gjalt-Jorn Peters, Eva de Hullu & Jacques van Lankveld"
date: "`r format(Sys.time(), '%H:%M:%S on %Y-%m-%d %Z (GMT%z)')`"
output: html_document
---

```{r setup, include=FALSE}
########################################################################
### Load packages
########################################################################
 
require('userfriendlyscience');  ### For convenience functions, e.g. 'safeRequire'
safeRequire('here');             ### To easily access files using 'relative paths'
safeRequire('plyr');             ### For easily processing and restructuring data
safeRequire('dplyr');            ### Also for easily processing and restructuring data
safeRequire('purrr');            ### Iteration and the %||% operator
safeRequire('lubridate');        ### For working with dates
safeRequire("googlesheets");     ### To import data from google sheets in metabefor
safeRequire('jsonlite');         ### To import a list of country codes in metabefor
safeRequire('knitr');            ### For kable
safeRequire('ufs');              ### 
safeRequire('data.tree');        ### To work with data structured in a tree in metabefor
safeRequire('devtools');         ### To install metabefor from github repo
                                 ### ... Which we then do here:
devtools::install_github("Matherion/metabefor");
require('metabefor');

########################################################################
### Settings
########################################################################

### By default hide R code
knitr::opts_chunk$set(echo = FALSE);
knitr::opts_chunk$set(comment = NA);

### Set path for query hit exports
queryHitExportPath <- here::here("queries");

### Set path for screening
screeningPath <- here::here("screening");

### Set path for any preliminary studies/work
prePath <- here::here("pre");

### Set path for extraction script template
extractionScriptTemplatePath <- here::here("extraction");

### Create object to keep track of queries
queries <- list();

```

## Pilot data

```{r process-pilot-data, results="asis"}

preDat <- importLimeSurveyData(datafile=file.path(prePath, "data", "survey_774372_R_data_file.csv"),
                               scriptfile=file.path(prePath, "data", "survey_774372_R_syntax_file.R"),
                               categoricalQuestions = c("expertise"));

varsToShow <- c(grep('corrections_', names(preDat), value=TRUE),
                'omissions',
                'expertise',
                'expertise_other',
                'comments');

for (currentVar in varsToShow) {
  ufs::cat0("\n\n### ", currentVar, "\n\n");
  ufs::cat0(paste0("\n- ", preDat[, currentVar], "\n"));
}

```


```{r first-query-setup}
queries[[length(queries) + 1]] <-
  list(date = ymd("2018-08-28"),
       query = query_requiredConcepts(conceptName="Exposure therapy query",
                                      query_conceptTerms(conceptName = "Cognitive Behavioral Therapy",
                                                         "cognitive behavio* therapy",
                                                         "cbt"),
                                      query_conceptTerms(conceptName = "Exposure Therapy",
                                                         "exposure"),
                                      query_conceptTerms(conceptName = "Target population",
                                                         "child*",
                                                         "adolescent*",
                                                         "youth"),
                                      query_conceptTerms(conceptName = "Disorder",
                                                         "anxiety",
                                                         "fear")),
       databases = list(psycinfo = list(interface = "ebsco",
                                        fileFormat = "ris"),
                        pubmed = list(interface= "pubmed",
                                      fileFormat = "ris")),
       fields = "title, abstract");

### Note that PsycINFO subsumes PsycARTICLES, and PubMed subsumes MEDLINE (see
### "Is PsycARTICLES cross-linked with any outside databases or journals?" at
### http://www.apa.org/pubs/databases/psycarticles/faq.aspx for PsycINFO and
### and http://askus.library.tmc.edu/faq/2018 for MEDLINE

```

## First query, executed at: `r queries[[1]]$date;`

The first query is:

```{r query1-visual, screenshot.force=FALSE}
plot(queries[[1]]$query);
```

In this plot, the 'AND' operator is visualised by a solid line, while the 'OR' operator is visualised by a dotted line.

In this query, the searched terms must occur in entries' `r queries[[1]]$fields` fields.

In the interface language of the PubMed interface to the PubMed database and the Ebscohost and Ovid interfaces to a variety of databases such as PsycINFO, PsycArticles, and MedLine, this query renders as:

```{r}
query_toInterfaceLang(queries[[1]]$query,
                      fields=queries[[1]]$fields);
```

The EbscoHost query was manually adjusted to:

    (TI ("cognitive behavio* therapy" OR "cbt") OR AB ("cognitive behavio* therapy" OR "cbt")) AND ((TI "exposure") OR (AB "exposure")) AND ((TI ("child*" OR "adolescent*" OR "youth")) OR (AB ("child*" OR "adolescent*" OR "youth"))) AND ((TI ("anxiety" OR "fear")) OR (AB ("anxiety" OR "fear")))



This query was run at `r queries[[1]]$date;` in PubMed (XXXX hits; file saved as <code>pubmed-`r queries[[1]]$date`.ris</code>) and PsycINFO accessed through EbscoHost (XXXX hits; file saved as <code>psycinfo-`r queries[[1]]$date`.ris</code>), and exported to RIS format (called 'medline' in PubMed). The RIS files were then imported in R using `metabefor`.

```{r echo=TRUE, eval=TRUE}

### Import PsycINFO hits
firstQueryIteration_psycinfo <-
  importRISlike(file.path(queryHitExportPath,
                          queries[[1]]$date,
                          paste0(queries[[1]]$date, "--",
                                 queries[[1]]$databases[[1]]$interface, "--",
                                 names(queries[[1]]$databases)[1], ".",
                                 queries[[1]]$databases[[1]]$fileFormat)),
                encoding="native.enc");

### Import PubMed hits
firstQueryIteration_pubmed <-
  importRISlike(file.path(queryHitExportPath,
                          queries[[1]]$date,
                          paste0(queries[[1]]$date, "--",
                                 queries[[1]]$databases[[2]]$interface, "--",
                                 names(queries[[1]]$databases)[2], ".",
                                 queries[[1]]$databases[[2]]$fileFormat)),
                encoding="native.enc");

### Merge the two sets of hits
firstQueryIteration <-
  findDuplicateReferences(primaryRefs = firstQueryIteration_psycinfo,
                          secondaryRefs = firstQueryIteration_pubmed,
                          duplicateFieldValue = "dupl",
                          newRecordValue = "PubMed",
                          duplicateValue = "duplicate (both PsycINFO and PubMed)",
                          originalValue = "PsycINFO");

### Generate bibtex keys
firstQueryIteration$output$records <-
  generateBibtexkeys(firstQueryIteration$output$records);

### Add query date identifier to bibtex keys
firstQueryIteration$output$records$bibtexkey <-
  paste0(firstQueryIteration$output$records$bibtexkey,
         "-", gsub("-", "", queries[[1]]$date));

screening1_filename <- paste0(queries[[1]]$date, "-screening.bib");

### Export the hits to bibtex for screening in JabRef
sysrevExport(firstQueryIteration,
             filename=file.path(screeningPath,
                                screening1_filename),
             screeningType="screening");

```

The merged list of query hits has now been exported to file <code>`r screening1_filename`</code> in directory "screening" and can be opened using JabRef, which can be downloaded from https://www.fosshub.com/JabRef.html.

## JabRef configuration

When opening a bibliographic library (i.e. a file with the extension `.bib`) in JabRef, it will show the entry table, which is a convenient way to inspect all entries (hits, references, articles, etc) in the library. To prepare JabRef for screening, two settings are important.

First, to change the fields that are visible in the overview table of all references (i.e. the entry table), open the 'Options' drop-down menu and select 'Preferences'. In the preferences dialog, open the 'Entry table columns' section:

![Figure 1: Screenshot of JabRef preferences dialog when the 'Entry table columns' section is opened.](../img/jabref--preferences--entry-table-columns.png)

There, the columns shown in the entry table can be edited in the 'Entry table columns' sections. A bit confusingly, this is done by adding *rows* in the table shown in this dialog. Each 'row' in this table represents a column in the entry table.

Note that in bibtex (and therefore JabRef), you can create new fields on the fly. In this case, use field 'screening1' for screening the hits of this first screening iteration: simply add this field name as a 'row' (column) in the entry table. This will show, for every entry, the contents of that field (if it has any).

Second, you need to be able to edit the content in that field. The entry table is very convenient to maintain an overview of the entries in the database, but cannot be used for editing. To edit an entry, double click it in the entry tabel. This opens the entry editor, which has a number of tabs. Each tab shows a number of fields which can then be edited.

These tabs can be configured by setting the 'General fields'. Open the 'Options' drop-down menu and select 'General Fields' to configure which fields are available in the different tabs when opening an entry. 

![Figure 2: Screenshot of JabRef dialog used to set the general fields.](../img/jabref--set-general-fields.png)

Add a dedicated field for the reviewing, showing only the title, abstract, and `screening1` fields. This allows you to focus on the relevant information while ignoring irrelevant and potentially biasing information (such as year, journal, and authors). Each row in this text area shows one tab. The first term on each row is the tab's name, followed by a colon (`:`) and then the fields shown in the tab, separated by semicolons (`;`). For example, you could add the following row:

`Screening Round 1:title;abstract;screening1`

## Screening process

For every entry, add the following text in the 'screening' field:

- If it is excluded, add the reason, specifically (these are ordered progressively; i.e. if one of the criteria matches, apply it and move on to the next entry):
    - **`dupl`** if the study is a duplicate of another entry;
    - **`noexper`** if the study does not have an experimental design;
    - **`nopopul`** if the study did not sample participants younger than 18 years;
    - **`noexpos`** if the study did not compare two groups that differ in the treatment in terms of exposure as a part of cognitive behavioral therapy;
    - **`nophobia`** if the study did not concern treatment for phobia disorders;
- If it is included, add **`incl`**.

So once JabRef is opened, when screening, make sure that the 'screening1' field is shown in the entry table (i.e. that it is one of the entry table columns), and create one entry editing tab using 'General Fields' that contains the fields `title`, `abstract`, and `screening1`. You can then use this tab for the screening. It is also convenient to show field `dupl` in either the entry table or the screening tab in the entry editor, because for duplicate records (that were identified as such - the algorithm may miss some duplicates of course), that field contains the text `dupl`.

Make sure to save the database with query hits under a different name than <code>`r screening1_filename`</code>. That is important because file <code>`r screening1_filename`</code> will get overwritten if this R Markdown file is executed again.

## Second query, executed at: 2018-05-23

The query was updated to:

```
NEWQUERY
```

This was run at 2018-05-23 in PubMed (61 hits) and PsycINFO accessed through EbscoHost (72 hits), and exported to the RIS format (called 'medline' in PubMed). The RIS files were then imported in R using `metabefor`.

```{r echo=TRUE, eval=FALSE}

### Import PsycINFO hits
secondQueryIteration_psycinfo <-
  importRISlike(file.path(queryHitExportPath,
                          "psycinfo-2018-05-23.ris"),
                encoding="native.enc");

### Import PubMed hits
secondQueryIteration_pubmed <-
  importRISlike(file.path(queryHitExportPath,
                          "pubmed-2018-05-23.ris"));

### Merge the two sets of hits
secondQueryIteration <-
  findDuplicateReferences(primaryRefs = secondQueryIteration_psycinfo,
                          secondaryRefs = secondQueryIteration_pubmed,
                          duplicateFieldValue = "dupl (2nd)",
                          newRecordValue = "PubMed (2nd)",
                          duplicateValue = "duplicate (both PsycINFO and PubMed; 2nd)",
                          originalValue = "PsycINFO (2nd)");

### Generate bibtex keys
secondQueryIteration$output$records <-
  generateBibtexkeys(secondQueryIteration$output$records);

### Add query date identifier to bibtex keys
secondQueryIteration$output$records$bibtexkey <-
  paste0(secondQueryIteration$output$records$bibtexkey,
         "-20180523");

### Import results from first query (these have been screened now)
firstQueryIteration_screened <-
  importBibtex(file.path(screeningPath,
                         "2018-05-14-screening#1.bib"));

### Merge the screened reference database from the first query
### with the database from the second query
secondQueryIteration_merged <-
  findDuplicateReferences(primaryRefs = firstQueryIteration_screened,
                          secondaryRefs = secondQueryIteration,
                          duplicateFieldValue = "Screened in first iteration",
                          newRecordValue = "From second query",
                          duplicateValue = "From first query (screened in first iteration)",
                          originalValue = "screening1");

### The new records are stored in secondQueryIteration_merged$output$newRecords, so we
### can copy these to the database from the first screening. We also store the entire
### database so that we can document the process (and if need be, check whether anything
### went wrong).

secondScreening <- firstQueryIteration_screened;

secondScreening$output$records <- rbind.fill(secondScreening$output$records,
                                             secondQueryIteration_merged$output$newRecords);

### Export the hits to bibtex for screening in JabRef
sysrevExport(secondQueryIteration_merged,
             filename=file.path(screeningPath,
                                "2018-05-23-fully-merged-database.bib"),
             screeningType="screening");

sysrevExport(secondScreening,
             filename=file.path(screeningPath,
                                "2018-05-23-screening.bib"),
             screeningType="screening");

```

The merged bibliographic database has been stored in the screening path (`r screeningPath`), to file `2018-05-23-screening.bib`. This file can now be opened in JabRef, and should be saved to a different filename before any edits are made (because, after all, the file named `2018-05-23-screening.bib` will be overwritten every time this script runs).

In this merged database, field 'screening1' has been preserved. Records where this field is empty, therefore, are from the second query, and should be screened in the second screening sweep.

## Generation of the Extraction Script

We will use a metabefor extraction script for the extraction of the data. The idea of this script is to extract the data from the original sources with a minimum of interpretation. The data is extracted into a machine-readable format, which then allows competely transparent further processing and synthesis.

These scripts are generated on the basis of two tables/spreadsheets. The first contains the entities to extract, such as study year, sample size, how variables were operationalised, and associations that were found. The second contains the valid values for each entity, to allow efficiently providing coders with examples, instructions, and to allow easy verification of the input.

```{r extraction-script-generation}

sheetsURL <- paste0("https://docs.google.com/spreadsheets/d/",
                    "1TpdpB926luKVy2tCwBusFkxZ7xv-BzdzzBjmOU26PI8");

valueTemplatesSheet <- "valueTemplates";
entitiesSheet <- "entities";

fullObject <-
  rxs_fromSpecifications(gs_url = sheetsURL,
                         entitiesFilename = file.path(extractionScriptTemplatePath,
                                                      "entities-local-copy.csv"),
                         valueTemplatesFilename = file.path(extractionScriptTemplatePath,
                                                            "valueTemplates-local-copy.csv"),
                         localBackup = list(entities = file.path(extractionScriptTemplatePath,
                                                                 "entities-local-copy.csv"),
                                            valueTemplates= file.path(extractionScriptTemplatePath,
                                                                      "valueTemplates-local-copy.csv"),
                                            definitions = NULL),
                         outputFile = file.path(extractionScriptTemplatePath,
                                                "extractionScriptTemplate.rxs.Rmd"),
                         returnFullObject = TRUE);

```

## List of active ingredients

```{r active-ingredient-list}

data.frame(Name=fullObject$rxsStructure$parsedEntities$extractionScriptTree$methods$variables$treatments$Get('title'),
           Description=fullObject$rxsStructure$parsedEntities$extractionScriptTree$methods$variables$treatments$Get('description')) %>%
  knitr::kable();

```
